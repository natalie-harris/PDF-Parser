"""
Natalie Harris, NIMBioS
5/26/23

This utility combines csv data from each research paper pdf generated by parser.py.
"""

import os
import pandas as pd
import geopy
import glob

folder_name = input("Input the folder path: ")
csv_files = glob.glob(folder_name + "/*.csv")
print(csv_files)

# not including 5a, 6a, 8 because they are all Hardy et al.
# ChatGPT cannot read the pictures in Hardy et al. so we can't compare data
study_indices = {
    "outbreak_data_Bouchard et al. 2018 -1.csv": 1, 
    "outbreak_data_Boulanger et al. 2012 SBW outbreaks 400 yrs.csv": 2,
    "outbreak_data_Fraver et al. 2006 time series SBW Maine.csv": 3,
    "outbreak_data_Navarro et al. 2018 space time SBW.csv": 4,
    "outbreak_data_Elliot 1960.csv": 5,
    "outbreak_data_Blais 1954.csv": 6,
    "outbreak_data_Blais 1981.csv": 7,
    "outbreak_data_Berguet et al. 2021 spatiotemp dyn 20th cent sbw.csv": 9
    }

data_list = []
for filename in csv_files:
    data = pd.read_csv(filename)
    data['file_name'] = os.path.basename(filename)
    data['study'] = data['file_name'].map(study_indices)
    data_list.append(data)

all_data = pd.concat(data_list, ignore_index=True)

all_data.to_csv(folder_name + '/' + folder_name + '.csv', index=False)
