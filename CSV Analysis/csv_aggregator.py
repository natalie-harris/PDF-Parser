"""
Natalie Harris, NIMBioS
5/26/23

This utility combines csv data from each research paper pdf generated by parser.py.
"""

import os
import pandas as pd
import glob

folder_name = input("Input the folder path: ")
csv_files = glob.glob(folder_name + "/*.csv")
print(csv_files)

# not including 5a, 6a, 8 because they are all Hardy et al.
# ChatGPT cannot read the pictures in Hardy et al. so we can't compare data
study_indices = {
    "outbreak_data_Bouchard et al. 2018 -1.csv": 1, 
    "outbreak_data_Boulanger et al. 2012 SBW outbreaks 400 yrs.csv": 2,
    "outbreak_data_Fraver et al. 2006 time series SBW Maine.csv": 3,
    "outbreak_data_Navarro et al. 2018 space time SBW.csv": 4,
    "outbreak_data_Elliot 1960.csv": 5,
    "outbreak_data_Blais 1954.csv": 6,
    "outbreak_data_Blais 1981.csv": 7,
    "outbreak_data_Berguet et al. 2021 spatiotemp dyn 20th cent sbw.csv": 9
    }

outbreak_occurence_values = {
    'no': 0,
    'yes': 1,
    'uncertain': 2
}

# concatenate all csv files
data_list = []
for filename in csv_files:

    data = pd.read_csv(filename)

    # add outbreak=no entries where gaps exist
    list_data_filled = []
    data = data.sort_values(['area', 'year'])
    for area in data['area'].unique():
        area_data = data[data['area'] == area]
        #print(area_data)
        min_year = area_data['year'].min()
        max_year = area_data['year'].max()
        latitude = area_data['latitude'].iloc[0]
        longitude = area_data['longitude'].iloc[0]
        all_years = pd.DataFrame({'year': range(min_year - 1, max_year + 2)}) # includes 5 years before and after outbreaks since we can assume they didn't have outbreaks
        all_years['area'] = area
        all_years['latitude'] = latitude
        all_years['longitude'] = longitude
        merged_data = pd.merge(all_years, area_data, how='left', on=['year', 'area', 'latitude', 'longitude'])
        merged_data['outbreak'].fillna('no', inplace=True)
        list_data_filled.append(merged_data)

    data = pd.concat(list_data_filled, ignore_index=True)

    data['file_name'] = os.path.basename(filename)
    data['study'] = data['file_name'].map(study_indices)
    data['outbreak'] = data['outbreak'].map(outbreak_occurence_values)
    data_list.append(data)

if len(data_list) > 0:
    all_data = pd.concat(data_list, ignore_index=True)
    all_data.to_csv(folder_name + '/' + folder_name + '.csv', index=False)
    all_data.to_excel(folder_name + '/' + folder_name + '.xlsx', index=False)
